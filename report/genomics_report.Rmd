---
title: "Genomics_report_v1"
author: "Huethercode"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: journal
  word_document:
    toc: true
  pdf_document:
    toc: true
    fig_caption: true
    df_print: kable
---

```{r setup_load_pkg, include=FALSE, dependson="packages" }
knitr::opts_chunk$set(include = FALSE)
#if (!require("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("karyoploteR")
#BiocManager::install("org.Hs.eg.db")
#BiocManager::install("ensemblVEP")

#sudo cp /home/linuxbrew/.linuxbrew/Cellar/gcc/14.2.0_1/lib/gcc/current/libstdc++.so.6 /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep CXXABI

library(vcfR)
library(ggplot2)
library(dplyr)
library(karyoploteR)
library(GenomicRanges)
library(DBI)
library(readr)
library(tinytex)
library(knitr)
library(kableExtra)

#hereditary genetics
library(VariantAnnotation)



```
# 1. Introduction and Data Import

The specific focus is Adulthood understanding of genomic observations.

This report provides a quality control (QC) analysis of the input Variant Call Format (VCF) file, summarizing key statistics and visualizations. 

## 2. Data Import, Preprocessing, QC
```{r data_import, include=FALSE}
knitr::opts_chunk$set(include = FALSE)
##################################################################
#Load Files
# set working directory with the files needed
#setwd("~/Documents/genomics/output/4c456a7a-e189-11ef-bb21-002436b6d0cf")
setwd("~/Documents/genomics/output/21a36b0e-e5ae-11ef-9dc1-002436b6d0cf")
#vcf_file <- "~/Documents/genomics/output/4c456a7a-e189-11ef-bb21-002436b6d0cf/bobby_exome_genotyped.ann.vcf"
#vcf_file <- "~/Documents/genomics/data/f1988686-db0b-4818-aa0a-d8720c520a23_genotyped.ann.vcf"
#vcf_file <- "~/Documents/genomics/output/21a36b0e-e5ae-11ef-9dc1-002436b6d0cf/Gs74Pkvkvl.vcf"
#vcf_file <- "4c456a7a-e189-11ef-bb21-002436b6d0cf.vcf"
vcf_file <- "21a36b0e-e5ae-11ef-9dc1-002436b6d0cf.vcf"

opencr_file<-"oc.tsv"
prs_file<-"prs.tsv"









if(!file.exists("gnomad_plot.png")){
  gnomad_plot<-"gnomad_plot.png"
}
if(!file.exists("percent_ancestry.png")){
  percent_ancestry_plot<-"percent_ancestry.png"
}

prs <- read_delim(prs_file, 
    delim = "\t", escape_double = FALSE, 
    trim_ws = TRUE)

  X250204_195258_export_variant <- read_delim(opencr_file, 
    delim = "\t", escape_double = FALSE, 
    trim_ws = TRUE, skip = 6)
  
#Reference Sets 
# Define ACMG secondary findings list of genes
ACMG_SF_v3.2 <- read.table("../../refdata/gene_list/ACMG_SF_v3.2.txt", quote="\"", comment.char="")

Adult_Actionability_Reports_Outcome_Intervention_Pairs_allColumns <- read_delim("../../refdata/actionbility/Adult Actionability Reports - Outcome-Intervention Pairs allColumns.tsv", 
    delim = "\t", escape_double = FALSE, 
    trim_ws = TRUE)

wellness <- read_delim("~/Documents/genomics/refdata/wellness/wellness.tsv", 
    delim = "\t", escape_double = FALSE, 
    trim_ws = TRUE)

#################################################################
vcf <- read.vcfR(vcf_file, verbose = FALSE)




# Filter out low-quality variants
quality_threshold <- 30
vcf <- vcf[as.numeric(vcf@fix[, "QUAL"]) >= quality_threshold, ]


# Extract genotype data
gt <- extract.gt(vcf, element = "GT", as.numeric = TRUE)

# Extract depth (DP) and genotype quality (GQ)
dp <- extract.gt(vcf, element = "DP", as.numeric = TRUE)
gq <- extract.gt(vcf, element = "GQ", as.numeric = TRUE)

# Convert to data frame for visualization
df <- data.frame(
  Sample = rep(colnames(dp), each = nrow(dp)),
  DP = as.vector(dp),
  GQ = as.vector(gq)
)

df <- df %>% filter(!is.na(DP) & !is.na(GQ))

```

## 3. VCF Quality Control Metrics
the VCF file is a general purpose variant format so there must be some knowledge behind what went into generating the file before it is useful.  The expectation here is the file contains variant level data, hopefully from broad panel, describing the germline variants identified.

Some metrics of interest if the vcf file fits this basic input requirement.

Metric	Value (Observed)	Threshold	Status
- Ts/Tv Ratio	ts_tv_ratio	> 2.0 (exome), > 1.8 (genome)	PASS/FAIL.  transition/transversion (Ti/Tv) ratio (transition: purine-based A↔G or transversion: pryimidine-based C↔T).  <1 indicates many false positive changes with 0.5 (ts:tv=2:4=0.5) being random. beyond 3 indicates a highly biased cohort of changes. This might be observed in targeted panels of GC rich regions. for general targeted a value of 1-3 is expected. 

- Mean Depth (DP)	mean(dp, na.rm = TRUE)	> 30 (exome), > 10 (genome)	PASS/FAIL.  Anything less than 10 the zygosity should be questioned but the call may not necessary be bad.  


- Genotype Quality (GQ)	mean(gq, na.rm = TRUE)	> 20	PASS/FAIL
- SNP Count	snp_count	N/A (context-dependent)	Info
- Indel Count	indel_count	N/A (context-dependent)	Info


```{r qc_summary, echo=FALSE}
knitr::opts_chunk$set(include = TRUE)
# Calculate Ts/Tv ratio manually
transitions <- c("A>G", "G>A", "C>T", "T>C")
transversions <- c("A>C", "A>T", "G>C", "G>T", "C>A", "C>G", "T>A", "T>G")

variants <- data.frame(
  REF = vcf@fix[, "REF"],
  ALT = vcf@fix[, "ALT"]
)

variants$Mutation <- paste(variants$REF, variants$ALT, sep = ">")

num_ts <- sum(variants$Mutation %in% transitions, na.rm = TRUE)
num_tv <- sum(variants$Mutation %in% transversions, na.rm = TRUE)
ts_tv_ratio <- num_ts / num_tv

#cat("Ts/Tv ratio:", ts_tv_ratio, "\n")

# Count SNPs and Indels based on REF and ALT fields
snp_count <- sum(nchar(variants$REF) == 1 & nchar(variants$ALT) == 1, na.rm = TRUE)
indel_count <- sum(nchar(variants$REF) > 1 | nchar(variants$ALT) > 1, na.rm = TRUE)

#cat("Number of SNPs:", snp_count, "\n")
#cat("Number of Indels:", indel_count, "\n")

#cat("Number of Genes with Variants:", gene_count, "\n")

# Calculate QC metrics
mean_depth <- mean(dp, na.rm = TRUE)
mean_gq <- mean(gq, na.rm = TRUE)
missing_data <- mean(is.na(gt)) * 100


# Define pass/fail criteria
ts_tv_status <- ifelse(ts_tv_ratio > 2.0, "PASS", "FAIL")
depth_status <- ifelse(mean_depth > 30, "PASS", "FAIL")
gq_status <- ifelse(mean_gq > 20, "PASS", "FAIL")

# Create QC summary table
qc_summary <- data.frame(
  Metric = c("Ts/Tv Ratio", "Mean Depth (DP)", "Mean Genotype Quality (GQ)", "Number of SNPs", "Number of Indels"),
  Value = c(ts_tv_ratio, mean_depth, mean_gq, snp_count, indel_count),
  Threshold = c("> 2.0", "> 30", "> 20", "N/A", "N/A"),
  Status = c(ts_tv_status, depth_status, gq_status, "Info", "Info")
)


```

```{r show_qc_summary, echo=FALSE, fig.height=5, fig.width=5}
knitr::opts_chunk$set(include = TRUE)
knitr::kable(qc_summary, caption = "QC summary table")
```


Metric	Value (Observed)	Threshold	Status
Ts/Tv Ratio	ts_tv_ratio	> 2.0 (exome), > 1.8 (genome)	PASS/FAIL
Mean Depth (DP)	mean(dp, na.rm = TRUE)	> 30 (exome), > 10 (genome)	PASS/FAIL
Genotype Quality (GQ)	mean(gq, na.rm = TRUE)	> 20	PASS/FAIL
SNP Count	snp_count	N/A (context-dependent)	Info
Indel Count	indel_count	N/A (context-dependent)	Info

## 4. Indel size distribution
```{r indel_dist, echo=FALSE}
knitr::opts_chunk$set(include = TRUE)

# Create a data frame for indels
indels <- variants[nchar(variants$REF) > 1 | nchar(variants$ALT) > 1, ]

# Classify indels as insertions or deletions
indels$Type <- ifelse(nchar(indels$REF) > nchar(indels$ALT), "Deletion", "Insertion")

# Calculate indel sizes
indels$Size <- abs(nchar(indels$REF) - nchar(indels$ALT))

# Create bins for indel sizes
bin_size <- 5
indels$SizeBin <- cut(indels$Size, breaks = seq(0, max(indels$Size, na.rm = TRUE) + bin_size, by = bin_size), include.lowest = TRUE)


# Plot indel size distribution
plot_indel_size<-ggplot(indels, aes(x = SizeBin, fill = Type)) +
  geom_bar(data = subset(indels, Type == "Deletion"), aes(y = after_stat(count)), position = position_nudge(x = -0.2), width = 0.4) +
  geom_bar(data = subset(indels, Type == "Insertion"), aes(y = after_stat(count)), position = position_nudge(x = 0.2), width = 0.4) +
  scale_fill_manual(values = c("Deletion" = "red", "Insertion" = "blue")) +
  labs(title = "Indel Size Distribution", x = "Indel Size (bp)", y = "Count") +
  theme_minimal()

plot_indel_size
```

## 4. Depth and Variant Density Across the Genome
```{r vcf-qc-plots_density, echo=FALSE, fig.width = 5, fig.height = 5}
knitr::opts_chunk$set(include = TRUE)

# Plot Depth Across the Genome on a Karyoplot as a Line Plot
kp <- plotKaryotype(genome = "hg19")# Normalize depth values between 0 and 1
depth_df <- data.frame(
  Chr = vcf@fix[, "CHROM"], 
  Position = as.numeric(vcf@fix[, "POS"]), 
  DP = rowMeans(dp, na.rm = TRUE)
)
depth_df$DP <- (depth_df$DP - min(depth_df$DP, na.rm = TRUE)) / (max(depth_df$DP, na.rm = TRUE) - min(depth_df$DP, na.rm = TRUE))
depth_df$Chr<-paste("chr", depth_df$Chr, sep="")

# Variant density data
variant_density <- data.frame(Chr = vcf@fix[, "CHROM"], Position = as.numeric(vcf@fix[, "POS"]))

# Plot Depth Across the Genome on a Karyoplot as a Line Plot
kp <- plotKaryotype(genome = "hg19")

#kpDataBackground(kp, data.panel = 1, r0=0, r1=0.8)
  kpAxis(kp, ymin=0.2, ymax=1, r0=0.05, r1=0.75, col="gray50", cex=0.2)
#  kpPoints(kp, chr = depth_df$Chr, x = depth_df$Position, y = depth_df$DP, ymin=0, ymax=1, r0=0.05, r1=0.75, col="black", pch=".", cex=2)
  
#kpLines(kp, chr = depth_df$Chr, x = depth_df$Position, y = depth_df$DP, col = "blue", lwd = 2)
#kpPlotDensity(kp, data = GRanges(seqnames = variant_density$Chr, ranges = IRanges(start = variant_density$Position, width = 1)), col = "red", border = "red")
kpPoints(kp, chr = depth_df$Chr, x = depth_df$Position, y = depth_df$DP, ymin=0.2, ymax=1, r0=0.05, r1=0.75, col = "blue", lwd = 2)


#kpPlotDensity(kp, data = GRanges(seqnames = variant_density$Chr, ranges = IRanges(start = variant_density$Position, width = 1)), col = "red", border = "red")

```

Observed locations accross the genome where variants are present.

## 5. Allele Frequency Distribution
```{r vcf-qc-plots_af, echo=FALSE, fig.height=5, fig.width=5, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(include = TRUE)
# Extract allele frequency (AF) values from the FORMAT field

allele_freqs <- extract.gt(vcf, element = "AF", as.numeric = TRUE)
colnames(allele_freqs)[1] <- "AF"

allele_data <- data.frame(
  DP = extract.gt(vcf, element = "DP", as.numeric = TRUE)[, 1],
  AO = extract.gt(vcf, element = "AO", as.numeric = TRUE)[, 1]
)

allele_data$AF<-allele_data$AO/allele_data$DP

# Plot allele frequency distribution
p_af<-ggplot(allele_data, aes(x = AF)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Allele Frequency Distribution", x = "Allele Frequency", y = "Count") +
  theme_minimal()
p_af
```


# 2. Ancestry
```{r ancestry_plots, eval=FALSE, fig.align="center", fig.cap=c("Ancestry_by_snv_story"), fig.height=5, fig.width=5, include=FALSE}
knitr::opts_chunk$set(include = TRUE)
if(!file.exists("percent_ancestry.png")){
  knitr::include_graphics("percent_ancestry.png")
  }

  knitr::include_graphics("gnomad_plot.png")



```

# 3. PGx
In the works!!

# 4. Hereditary Genetics
```{r hereditary-genetics, include=FALSE}
#open-cravat annotation: Manual Step: run annotations: Clinvar (2nd),  REVEL, alpha missesense, bayesdel,  pharmgkb: export coding
#B: Score... 104 #fix space
#O: Score... 115 #fix space

acmg_var<- X250204_195258_export_variant %>% 
  filter(Gene %in% ACMG_SF_v3.2$V1) %>%
  filter(Allele_Origin=='germline')

#Filtering:  Revel=Score...115 >=0.4, clinvar pathogenic, bayesdel=`Rank_Score (no MaxAF)`>=.5, alphamissense=  `Score...14`, exclude benign
variant_high <- acmg_var %>%
  filter(`Score...115`>=0.4| grepl('athog', Clinical_Significance) | `Rank_Score (no MaxAF)`>=.5 | Sequence_Ontology %in% c("complex_substitution","start_lost","inframe_deletion","frameshift_elongation","frameshift_truncation","stop_gained")) %>%
  filter(!(grepl('enign', Clinical_Significance))) %>%
  filter(Sequence_Ontology!="synonymous_variant") %>%
  distinct(Gene,cDNA_change,Protein_Change, AF,DP,`Score...115`,`Rank_Score (no MaxAF)`,`Score...14`, Clinical_Significance,Chrom...1,Position,Ref_Base,Alt_Base) %>%
  arrange(-`Score...115`)


aar_genes<-Adult_Actionability_Reports_Outcome_Intervention_Pairs_allColumns %>%
  tidyr::separate_longer_delim(`Gene/Variant`, delim = ",") %>%
  distinct(`Gene/Variant`,Condition,Outcome) 

aar_gene_var<-merge(X250204_195258_export_variant, aar_genes, by.x=c('Gene'), by.y=c('Gene/Variant'), all.y=TRUE)

aar_gene_var_out <- aar_gene_var %>%
  filter(aar_gene_var$Allele_Origin=='germline') %>%
  filter(`Score...115`>=0.4| grepl('athog', Clinical_Significance) | `Rank_Score (no MaxAF)`>=.5 | Sequence_Ontology %in% c("complex_substitution","start_lost","inframe_deletion","frameshift_elongation","frameshift_truncation","stop_gained")) %>%
  filter(!(grepl('enign', Clinical_Significance))) %>%
  filter(Sequence_Ontology!="synonymous_variant") %>%
  distinct(Gene,cDNA_change,Protein_Change, AF,DP,`Score...115`,`Rank_Score (no MaxAF)`,`Score...14`, Condition,Outcome,Clinical_Significance) %>%
  arrange(-`Score...115`)


```

```{r HighImpactVariants, fig.width = 5, fig.height = 5}
knitr::opts_chunk$set(include = TRUE)
knitr::kable(variant_high, caption = "High Impact Variants")

```

Findings from the 81 ACMG secondary findings list of genes.  The list contains any variant with a clinvar pathogenic, or high revel, alpha missense or bayesdel score. All clinvar benign and synonymous variants have been removed.

```{r ActionabiltyVariants, fig.width = 5, fig.height = 5}
knitr::opts_chunk$set(include = TRUE)
knitr::kable(aar_gene_var_out, caption = "Actionabilty Variants")
```

These are the high value genes from the ClinGen actionability gene list.  These are a collection of 343 gene-outcome-intervention gene sets. 

# 5. Wellness
```{r wellness, include=FALSE}
# include list of genes and wellness categories
#For wellness we are looking for gene disruption, any lof alteration/ high impact alteration.
germline_variant<-X250204_195258_export_variant  %>%
  filter(Allele_Origin=='germline')

wellness_var_raw<- merge(germline_variant, wellness, by.x=c("Gene"), by.y=c("gene"), all.y=TRUE)

wellness_var<-wellness_var_raw %>%
  dplyr::select(Gene,Sequence_Ontology,cDNA_change,Protein_Change,Score...14,`Rank_Score (no MaxAF)`,`Allele_Frequencies TGP`,Chrom...1,VCF_Position,`VCF_Ref Allele`,`VCF_Alt Allele`,AF,DP, Score...115,type)

#needs further data but guess LOF variant in these genes indicate high impact. 
#Filtering:  Revel=Score...115 >=0.4, OR bayesdel=`Rank_Score (no MaxAF)`>=.5, alphamissense=  `Score...14`,
#HIGH IMPACT:Score...115 >=0.75, OR bayesdel=`Rank_Score (no MaxAF)`>=.75, alphamissense=  `Score...14` >.75
#MEDIUM IMPACT: :Score...115 >=0.5, OR bayesdel=`Rank_Score (no MaxAF)`>=.5, alphamissense=  `Score...14` >.5
#ELSE LOW IMPACT

wellness_var<-wellness_var %>% mutate(impact=case_when(
  Score...115 >=0.75 | `Rank_Score (no MaxAF)`>=.75 | `Score...14` >.75 ~ 1,
  Score...115 >=0.5 | `Rank_Score (no MaxAF)`>=.5 | `Score...14` >.5 ~ 2, 
  is.na(Score...115) | is.na(`Rank_Score (no MaxAF)`) | is.na(`Score...14` >.5) ~ 4,   
  TRUE ~ 3)
            ) %>%
  group_by(type) %>%
  summarise(Gene = paste(Gene, collapse = ", "),
      Highest_Impact = min(impact, na.rm = TRUE)) %>%
  arrange(Highest_Impact)


```

```{r wellness_table, fig.width = 5, fig.height = 5}
knitr::opts_chunk$set(include = TRUE)
knitr::kable(wellness_var, caption = "Wellness Table")
```
Needs further data and filtering but guess LOF variant in these genes indicate high impact. Specifically impact/occurrence of trait are described as:
#HIGH IMPACT (1): Revel>=0.75, OR bayesdel>=.75 or alphamissense >.75
#MEDIUM IMPACT (2): Revel>=0.5, OR bayesdel>=.5 or alphamissense >.5
#LOW IMPACT (3): Revel<0.5, OR bayesdel<.5 or alphamissense <.5
#Unkown IMPACT (4)


# 6. PRS categories
Polygenic Risk Score Knowledge Base is used for calculating polygenic risk scores from given in
put files using GWAS data pulled from the GWAS Catalog.

- **Study ID** -- The study identifier assigned by the GWAS Catalog (or the user if they uploaded their own GWAS summary statistics)
- **Reported Trait** -- Trait based on the phenotype being studied, as described by the authors
- **Trait** -- Trait assigned by the GWAS Catalog, standardized from the Experimental Factor Ontology
- **Citation** -- The citation of the study
- **P-Value Annotation** -- The probability that the risk allele confers the amount of risk stated
- **Beta Annotation** --  Computed in the GWAS study, a numerical value that indicates the increase or decrease in the genetic risk per unit.
- **Score Type** -- This indicates if the study used odds ratios or beta values
- **Units (if applicable)** -- This column will contain the beta units if the Score Type is beta. 
- **SNP Overlap** -- Details the number of SNPs that are in the sample vcf/txt file which are 1. in the study, 2. not excluded from the calculation (see below), and 3. not removed from the calculation due to linkage-disequilibrium clumping.
- **SNPs Excluded Due To Cutoffs** -- Details the number of snps excluded from the study calculation due to p-value cutoff or minor allele frequency threshold
- **Included SNPs** -- The total number of SNPs included in the calculation
- **Score Type** -- This indicates if the study used odds ratios or beta values. Computed in the GWA study, a numerical value of the odds that those in the case group have the allele of interest over the odds that those in the control group have the allele of interest.
- **Units (if applicable)** -- This column will contain the beta units if the Score Type is beta. 
- **SNP Overlap** -- Details the number of SNPs that are in the sample vcf/txt file which are 1. in the study, 2. not excluded from the calculation (see below), and 3. not removed from the calculation due to linkage-disequilibrium clumping.
- **SNPs Excluded Due To Cutoffs** -- Details the number of snps excluded from the study calculation due to p-value cutoff or minor allele frequency threshold
- **Included SNPs** -- The total number of SNPs included in the calculation
- **Used Super Population** -- The super population used for linkage disequillibrium
- **Percentile** -- Indicates the percentile rank of the samples polygenic risk score 
- **Protective Variants** -- Variants that are protective against the phenotype of interest
- **Risk Variants** -- Variants that add risk for the phenotype of interest
- **Variants Without Risk Alleles** -- Variants that are present in the study, but the sample does not possess the allele reported with association. Note that a SNP may be in this list and also in the Protective Variants or Risk Variants list. This is caused by an individual being heterozygous for the alleles at that point. 
- **Variants in High LD** -- Variants that are not used in the calculation, due to them being in high linkage disequillibrium with another variant in the study. 

```{r prs, echo=FALSE}
knitr::opts_chunk$set(include = TRUE)
##https://prs.byu.edu/cli_download.html

#need to annotate these scores by traits from  https://www.pgscatalog.org/browse/traits/. there are about a dozen categories.  makes interpreting easier.
#prs %>% distinct(Trait)  to one of these:

#Biological process39 PGS
#Body measurement302 PGS
#Cancer737 PGS
#Cardiovascular disease401 PGS
#Cardiovascular measurement304 PGS
#Digestive system disorder423 PGS
#Hematological measurement401 PGS
#Immune system disorder232 PGS
#Inflammatory measurement50 PGS
#Lipid or lipoprotein measurement435 PGS
#Liver enzyme measurement40 PGS
#Metabolic disorder278 PGS
#Neurological disorder282 PGS
#Other disease308 PGS
#Other measurement1803 PGS
#Other trait168 PGS
#Sex-specific PGS18 PGS


prs$`Polygenic Risk Score`<-as.double(prs$`Polygenic Risk Score`)

high_prs_risk<-prs %>% 
  filter(`Score Type`=='OR') %>% 
  filter(`Polygenic Risk Score` !="NF") %>% 
  arrange(-`Polygenic Risk Score`)

ggplot(high_prs_risk,aes(`Polygenic Risk Score`,reorder(`Reported Trait`,high_prs_risk$`Polygenic Risk Score`)))+
  geom_point()+ 
  geom_vline(xintercept=0)+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

high_prs_risk_table <- high_prs_risk %>% 
  filter(`Polygenic Risk Score`>=1.5) %>% 
  dplyr::select(`Reported Trait`,Trait,`Polygenic Risk Score`,Percentile)

```

High odds ratio calls

```{r prs_beta, echo=FALSE}
knitr::opts_chunk$set(include = TRUE)

high_prs_beta<-prs %>% 
  filter(`Score Type`=='beta') %>% 
  filter(`Polygenic Risk Score` !="NF") %>% 
  filter(`Polygenic Risk Score`>=0.2 | `Polygenic Risk Score`<=-0.4) %>%
  arrange(-`Polygenic Risk Score`)

ggplot(high_prs_beta,aes(`Polygenic Risk Score`,reorder(`Reported Trait`,high_prs_beta$`Polygenic Risk Score`)))+
  geom_point()+ 
  geom_vline(xintercept=0)+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

high_prs_beta_table <- high_prs_beta %>% 
  filter(`Polygenic Risk Score`>=1 | `Polygenic Risk Score`<=-1) %>% 
  dplyr::select(`Reported Trait`,Trait,`Polygenic Risk Score`,Percentile)


```

```{r high_risk_table, echo=FALSE, fig.height=5, fig.width=5}
knitr::opts_chunk$set(include = TRUE)
knitr::kable(high_prs_risk_table, caption = "High Risk Categories")
```
Traits with an Odds Ratio greater than 1.5.  Be sure to check the percentile as a measure of impact.


```{r high_beta_risk_table, echo=FALSE, fig.height=5, fig.width=5}
knitr::opts_chunk$set(include = TRUE)
knitr::kable(high_prs_beta_table, caption = "High Beta Risk Categories")
```
Traits with an Beta Ratio greater 1 or less than 1.  Be sure to check the percentile as a measure of impact.

#Conclusions Prompt 

Chatgpt prompt: help summarize the main take home points in the personalized genomics report. Give a overall summary with key insights. Provide a table of insights and suggest some life style action changes with details. give links when appropriate, exact action items and expected change.




# References
- ** R modules **
1. R
2. vcfR
3. ggplot2
4. karyoploteR

VCF QC
1. titv https://academic.oup.com/bioinformatics/article/31/3/318/2366248

Ancestry
1. snvstory:

PRS
1. https://www.nature.com/articles/s42003-022-03795-x 
